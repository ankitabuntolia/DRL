{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_Technical_Tutorial.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ankitabuntolia/DRL/blob/main/02_Technical_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e5BB3G1hXL5"
      },
      "source": [
        "---\n",
        "Before you start exploring this notebook check if GPU support is enabled.\n",
        "To enable the GPU backend for your notebook, go to **Edit** â†’ **Notebook Settings** and set **Hardware accelerator** to **GPU**. \n",
        "For this notebook GPU support is not required but for future exercises it will be necessary.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D64rNsQCyL6Q"
      },
      "source": [
        "# Install OpenAI Gym and dependencies to render the environments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqL6W_Gkgp9a"
      },
      "source": [
        "# Install some dependencies\n",
        "!apt update\n",
        "!apt-get install -y xvfb x11-utils ffmpeg\n",
        "!pip install gym pyvirtualdisplay==0.2.* PyOpenGL==3.1.* PyOpenGL-accelerate==3.1.*\n",
        "# Install some environments\n",
        "!pip install gym[box2d]\n",
        "!pip install gym[atari]\n",
        "!pip install procgen\n",
        "# Bonus PyBullet (open source alternative to MuJoCo)\n",
        "!pip install stable-baselines3[extra] pybullet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBUs4yMsgRSz"
      },
      "source": [
        "# Import necessary modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ECmcPAOnhR4"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "# file handling and misc utilities\n",
        "import os, shutil\n",
        "import glob, io, base64\n",
        "from tqdm.notebook import tqdm as tqdm\n",
        "\n",
        "# Environment import and set logger level to display error only\n",
        "import gym\n",
        "from gym import logger as gymlogger, envs\n",
        "gymlogger.set_level(40) #error only\n",
        "\n",
        "# Monitor wrapper to capture videos\n",
        "from gym.wrappers import Monitor\n",
        "\n",
        "# Pybullet environmetn registration\n",
        "import pybullet_envs\n",
        "\n",
        "# Plotting and notebook imports\n",
        "from IPython.display import HTML, clear_output\n",
        "from IPython import display\n",
        "\n",
        "# start virtual display\n",
        "from pyvirtualdisplay import Display\n",
        "pydisplay = Display(visible=0, size=(640, 480))\n",
        "pydisplay.start()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsi0AtmRu36c"
      },
      "source": [
        "# Utility methods to capture and show videos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyN5yRYY0v7u"
      },
      "source": [
        "\"\"\"\n",
        "Utility functions to enable video recording of gym environment and displaying it\n",
        "\"\"\"\n",
        "def wrap_env(env_id, env):\n",
        "    \"\"\"\n",
        "    Wrapper for recording video of the environment.\n",
        "    \"\"\"\n",
        "    outdir = f\"./videos/{env_id}\"\n",
        "    if os.path.exists(outdir):\n",
        "        shutil.rmtree(outdir)\n",
        "    os.makedirs(outdir, exist_ok=True)\n",
        "    env = Monitor(env, outdir, force=True)\n",
        "    return env, outdir\n",
        "\n",
        "def concatenate_videos(video_dir):\n",
        "    \"\"\"\n",
        "    Merge all mp4 videos in video_dir.\n",
        "    \"\"\"\n",
        "    outfile = os.path.join(video_dir, 'merged_video.mp4')\n",
        "    cmd = \"ffmpeg -i \\\"concat:\"\n",
        "    mp4list = glob.glob(os.path.join(video_dir, '*.mp4'))\n",
        "    tmpfiles = []\n",
        "    # build ffmpeg command and create temp files\n",
        "    for f in mp4list:\n",
        "        file = os.path.join(video_dir, \"temp\" + str(mp4list.index(f) + 1) + \".ts\")\n",
        "        os.system(\"ffmpeg -i \" + f + \" -c copy -bsf:v h264_mp4toannexb -f mpegts \" + file)\n",
        "        tmpfiles.append(file)\n",
        "    for f in tmpfiles:\n",
        "        cmd += f\n",
        "        if tmpfiles.index(f) != len(tmpfiles)-1:\n",
        "            cmd += \"|\"\n",
        "        else:\n",
        "            cmd += f\"\\\" -c copy  -bsf:a aac_adtstoasc {outfile}\"\n",
        "    # execute ffmpeg command to combine videos\n",
        "    os.system(cmd)\n",
        "    # cleanup\n",
        "    for f in tmpfiles + mp4list:\n",
        "        if f != outfile:\n",
        "            os.remove(f)\n",
        "    # --\n",
        "    return outfile\n",
        "\n",
        "def show_video(video_dir):\n",
        "    \"\"\"\n",
        "    Show video in the output of a code cell.\n",
        "    \"\"\"\n",
        "    # merge all videos\n",
        "    mp4 = concatenate_videos(video_dir)    \n",
        "    if mp4:\n",
        "        video = io.open(mp4, 'r+b').read()\n",
        "        encoded = base64.b64encode(video)\n",
        "        display.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "                    loop controls style=\"height: 400px;\">\n",
        "                    <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "                </video>'''.format(encoded.decode('ascii'))))\n",
        "    else: \n",
        "        print(\"Could not find video\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "De3CuyBLgXos"
      },
      "source": [
        "# (Optional) Setup Google Drive mount to store your results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vpd2i1MumjP0"
      },
      "source": [
        "mount_google_drive = True\n",
        "if mount_google_drive:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    os.listdir('/content/drive/My Drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3uXYNSFfcnE"
      },
      "source": [
        "# List all registered environments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUzICjkwfZHB"
      },
      "source": [
        "envids = [spec.id for spec in envs.registry.all()]\n",
        "for envid in sorted(envids):\n",
        "    print(envid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YprC3YXff8Th"
      },
      "source": [
        "## Create an agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXVo_SNsvcU7"
      },
      "source": [
        "Since we are interested in environments we use a very simple agent that chooses a random action at every state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCwZoDalgPAZ"
      },
      "source": [
        "class RandomAgent(object):\n",
        "    \"\"\"The world's simplest agent!\"\"\"\n",
        "    def __init__(self, action_space):\n",
        "        self.action_space = action_space\n",
        "\n",
        "    def act(self, observation):\n",
        "        return self.action_space.sample()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApAhXO7NvrLN"
      },
      "source": [
        "# Interacting with the environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIQtp9v8fOEc"
      },
      "source": [
        "def run_environment(env_id, n_episodes=10):    \n",
        "    # Make the environment by calling gym.make with the name of our\n",
        "    # requested environment. You can directly instantiate an environment\n",
        "    # as well, e.g. if you made your own.\n",
        "    if \"procgen\" in env_id:\n",
        "        env = gym.make(env_id, render_mode=\"rgb_array\")\n",
        "        env.metadata[\"render.modes\"] = [\"human\", \"rgb_array\"]\n",
        "    elif \"pybullet\" in env_id:\n",
        "        env = gym.make(env_id)\n",
        "    else:\n",
        "        env = gym.make(env_id)\n",
        "    \n",
        "    # Print state and action space\n",
        "    print(f\"State Space:  {env.observation_space}\")\n",
        "    print(f\"Action Space: {env.action_space}\")\n",
        "\n",
        "    # we wrap our environment to record the video\n",
        "    # often, wrappers are used to implement frame stacking or skipping,\n",
        "    # sticky actions or parallelization\n",
        "    env, video_dir = wrap_env(env_id, env)\n",
        "\n",
        "    # now we seed the environment to get (somewhat) reproducible results\n",
        "    if not \"procgen\" in env_id:\n",
        "        env.seed(42)\n",
        "\n",
        "    # create our agent\n",
        "    agent = RandomAgent(env.action_space)\n",
        "\n",
        "    # setup some variables\n",
        "    cum_reward = 0\n",
        "    \n",
        "    # reset the environment, beginning a new episode\n",
        "    observation = env.reset()\n",
        "\n",
        "    # let the agent interact with the environment\n",
        "    for i in tqdm(range(n_episodes)):\n",
        "        done = False\n",
        "\n",
        "        while not done:\n",
        "            # get the next action from our agent\n",
        "            action = agent.act(observation)\n",
        "\n",
        "            # perform that action in the environment\n",
        "            observation, reward, done, _ = env.step(action)\n",
        "            cum_reward += reward\n",
        "            \n",
        "            # check if the episode is finished\n",
        "            if done:\n",
        "                observation = env.reset()\n",
        "\n",
        "    # close the environment\n",
        "    env.close()\n",
        "\n",
        "    # print the cumulative reward\n",
        "    print(f\"Avg. Reward: {cum_reward / n_episodes}\")\n",
        "\n",
        "    # now lets see what the agent did\n",
        "    show_video(video_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjjQ7aH5zItE"
      },
      "source": [
        "## Control"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVos8oxA3xd9"
      },
      "source": [
        "run_environment(\"CartPole-v1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiIF0b1y4Dnq"
      },
      "source": [
        "run_environment(\"MountainCar-v0\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8_nq0Zo_GA-"
      },
      "source": [
        "## Box-2D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcogOQ5HpOv4"
      },
      "source": [
        "run_environment(\"LunarLanderContinuous-v2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foflJHPizNGL"
      },
      "source": [
        "## Atari"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kERHu86ykVW3"
      },
      "source": [
        "run_environment(\"Breakout-v4\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgkrTqqFkb9L"
      },
      "source": [
        "run_environment(\"Boxing-v4\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bC3qtq1fzOil"
      },
      "source": [
        "## ProcGen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6hvHCex7LAT"
      },
      "source": [
        "run_environment(\"procgen:procgen-coinrun-v0\", n_episodes=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UV2932PC7XIJ"
      },
      "source": [
        "run_environment(\"procgen:procgen-chaser-v0\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xd3mHgs67aA3"
      },
      "source": [
        "run_environment(\"procgen:procgen-bossfight-v0\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xz3HKEbwrODk"
      },
      "source": [
        "## PyBullet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqQ_FBN1m-qa"
      },
      "source": [
        "run_environment(\"HalfCheetahBulletEnv-v0\", n_episodes=1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}